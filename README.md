# Modeling-Heart-Failure-Risk-Using-Bayesian-Networks
ðŸ©º Modeling Heart Failure Risk Using Bayesian NetworksA Transparent and Probabilistic Approach to Clinical Decision Support (ADSP 32014 IP01: Bayesian Machine Learning) 1111Project OverviewThis project explores the use of Bayesian Networks (BN) for heart disease risk prediction using the Heart Failure Prediction Dataset (Kaggle)2. In high-stakes domains like clinical risk assessment, interpretability and uncertainty quantification are critical, yet often lacking in traditional "black-box" machine learning models3333.Our primary goal was to develop a transparent, probabilistic model that maintains competitive predictive performance while offering fully calibrated, evidence-based reasoning444.Key FindingsHigh Predictive Power: the Bayesian Network achieved an ROC-AUC of 0.916 5, nearly matching the top-performing discriminative model (Logistic Regression, AUC 0.930)6666.Robust Calibration: the BN demonstrated superior probability calibration 7 (Brier Score 0.125) 88, providing highly reliable uncertainty estimates essential for clinical use999.White-Box Interpretability: the model supports transparent, scenario-based probabilistic queries, allowing clinicians to understand why a specific risk was assigned1010101010.ðŸ’» Methodology1. Data PreprocessingThe model was trained on 918 real-world patient records 11from the Heart Failure Prediction Dataset12.To align with Bayesian Network requirements and clinical standards, continuous numerical features were converted into clinically meaningful, interpretable bins (discretization)13.FeatureExample Discretization Bins Age{<40, 40-55, 55-70, $\ge$70} 15RestingBP{<120, 120-140, 140-160, $\ge$160} 16Cholesterol{<200, 200-240, $\ge$240} 172. Bayesian Network (BN) ModelingThe BN was constructed using the bnlearn and pgmpy libraries1818.Structure Learning: We used Hill-Climbing with the Bayesian Information Criterion (BIC) score to learn the Directed Acyclic Graph (DAG) structure that best explains the dependencies between risk factors1919.Parameter Learning: Bayesian Estimation with Dirichlet priors was used to estimate the Conditional Probability Distributions (CPDs) for each node20202020.The resulting structure explicitly models conditional dependencies between clinical factors21:The BN structure reveals key relationships, such as the strong influence of the ST_Slope ECG result on the HeartDisease diagnosis22.3. Probabilistic Inference & PredictionThe BN was evaluated by computing the posterior probability:$$P(\text{HeartDisease} = 1 \mid \text{evidence})$$2323232323for each patient in the test set using Variable Elimination24.ðŸ“ˆ Results and EvaluationModel Performance Metrics 25The BN proved highly competitive, particularly in terms of probabilistic reliability.Model ROC-AUC (Discrimination) Accuracy Brier Score (Calibration Error) Logistic Regression 300.930 310.886 32N/A 33Decision Tree (Max Depth 4) 340.870 350.804 36N/A 37Bayesian Network 380.916 39N/A 400.125 41Conclusion: The BN (0.916 AUC) is robust and maintains high discrimination42. The low Brier Score (0.125) confirms the BN's probabilities are highly reliable43. The BN offers the best blend of predictive power and statistical reliability/interpretability44.Discrimination (ROC Curve) 45The ROC curve shows the BN's (green line) ability to rank patients by risk is significantly better than the Decision Tree and close to the Logistic Regression model46.Calibration (Calibration Curve) 47The calibration curve demonstrates the BN's superior ability to provide reliable probability estimates48. The BN (green line) tracks the "Perfect" line (dashed black) more closely than the Decision Tree (orange) and exhibits highly stable calibration49.Interpretable Clinical Queries 50The BN's structure allows for transparent, scenario-based inference, directly supporting clinician trust51.Scenario 1: Elderly with Symptoms52:Evidence: $\text{Age} \ge 70$ AND $\text{Exercise Angina} = Y$ 53$P(\text{HeartDisease} = 1 \mid \text{Evidence}) = 0.588$ 54(Query shows a high likelihood of disease given the compounded risk factors.) 55Scenario 2: Young, Healthy ECG56:Evidence: $\text{Age} < 40$ AND $\text{ST\_Slope} = \text{Up}$ AND $\text{Oldpeak} \le 0$ 57$P(\text{HeartDisease} = 1 \mid \text{Evidence}) = 0.265$ 58(Protective factors significantly lower the estimated risk, providing transparent justification.) 59âœ¨ Generative AI Application: Synthetic DataAs a generative model, the BN can simulate realistic patient data, a key application in ADSP60.Conditional Sampling 61We generated 1,000 synthetic patient profiles conditioned on evidence (e.g., $\text{Age} \ge 70$) to model specific patient cohorts62.Code Snippet:Pythonsampler = BayesianModelSampling(bn)
synthetic_data = sampler.rejection_sample(
    evidence=[('Age_bin', '>=70')],
    size=1000
)
# Estimated P(HeartDisease=1 | Age_bin>=70) from samples â‰ˆ 0.502
``` [cite: 97, 98, 99, 100, 101, 104]

Validation: The empirical risk (47.6%) derived from the samples aligned with the analytical inference results63636363.UtilityResearch Utility: Augmenting small datasets for rare subgroups64.Privacy Utility: Sharing statistical properties of patient data without exposing real PHI (Protected Health Information)65.ðŸš€ ConclusionThe Bayesian Network is the optimal model for this high-stakes task66. It provides an unparalleled combination of:Performance (AUC 0.916, Brier 0.125) 67Interpretability (Supports exact probabilistic queries) 68Generative AI (Demonstrates utility in synthetic data generation) 69
